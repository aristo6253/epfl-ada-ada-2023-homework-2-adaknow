{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1d0380f",
   "metadata": {},
   "source": [
    "# Homework 2 (HW2)\n",
    "By the end of this homework, we expect you to be able to:\n",
    "\n",
    "- Preprocess data and make it amenable to statistical analysis and machine learning models;\n",
    "- Train and test out-of-the-box machine learning models in Python;\n",
    "- Carry out simple multivariate regression analyses;\n",
    "- Use techniques to control for covariates;\n",
    "- Conduct an observational study and reason about its results.\n",
    "\n",
    "---\n",
    "\n",
    "- Homework release: Fri 17 Nov 2023\t\n",
    "\n",
    "- **Homework Due**: Fri 01 Dec 2023, 23:59\t\n",
    "\n",
    "- Grades released: Mon 11 Dec 2023\t\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Some rules\n",
    "1. You are allowed to use any built-in Python library that comes with Anaconda. If you want to use an external library, you may do so, but must justify your choice.\n",
    "\n",
    "2. Make sure you use the `data` folder provided in the repository in read-only mode. (Or alternatively, be sure you don’t change any of the files.)\n",
    "\n",
    "3. Be sure to provide a concise textual description of your thought process, the assumptions you made, the solution you implemented, and explanations for your answers. A notebook that only has code cells will not suffice.\n",
    "\n",
    "4. For questions containing the **/Discuss:/** prefix, answer not with code, but with a textual explanation **(in markdown)**.\n",
    "\n",
    "5. Back up any hypotheses and claims with data, since this is an important aspect of the course.\n",
    "\n",
    "6. Please write all your comments in **English**, and use meaningful variable names in your code. Your repo should have a single notebook (plus the required data files) in the master/main branch. **If there are multiple notebooks present, we will not grade anything.**\n",
    "\n",
    "7. We will **not run your notebook for you!** Rather, we will grade it as is, which means that only the results contained in your evaluated code cells will be considered, and we will not see the results in unevaluated code cells. Thus, be sure to hand in a **fully-run and evaluated notebook**. In order to check whether everything looks as intended, you can check the rendered notebook on the GitHub website once you have pushed your solution there.\n",
    "\n",
    "8. In continuation to the previous point, interactive plots, such as those generated using the `plotly` package, should be strictly avoided!\n",
    "\n",
    "9. Make sure to print results and/or dataframes that confirm you have properly addressed the task.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "68937ccd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T17:54:27.233757Z",
     "start_time": "2023-11-17T17:54:26.757026Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# regression / matching\n",
    "import statsmodels.formula.api as smf\n",
    "import networkx as nx\n",
    "import statsmodels.graphics.regressionplots as smg\n",
    "\n",
    "# machine lerning\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# misc\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb04befc",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "After two years, the EPFL Baseball Club is broke. The new Dean transferred all funds to EPFL's new poster child: its super-competitive Pétanque club. After struggling so much to learn about baseball, you have unfortunately been laid off...\n",
    "\n",
    "*(...) 1 month after, you manage to get another job (!) (...)*\n",
    "\n",
    "Congratulations! You have just been hired as a data scientist at the Association for Computational Linguistics (ACL), a professional organization for people working on natural language processing. The ACL organizes several of the top conferences and workshops in the field of computational linguistics and natural language processing.\n",
    "Your boss, Dr. Tiancheng, knows of your expertise in observational studies and asks you to investigate a question that’s been bothering everyone who has ever submitted a paper to a conference: should I spend time on writing rebuttals?\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Rebuttals, conferences, and getting your papers accepted\n",
    "\n",
    "Rebuttals in ACL (Association for Computational Linguistics) conferences and in many other academic conferences are an important part of the peer-review process. They allow authors of submitted papers to respond to the reviews and comments provided by the reviewers before a final decision is made regarding the acceptance of the paper. Here's how the rebuttal process typically works in ACL conferences:\n",
    "\n",
    "- Paper Submission: Authors submit their research papers to the ACL conference for review. These papers present novel research findings in computational linguistics, natural language processing, and related areas.\n",
    "- Peer Review: The papers undergo a peer-review process after the initial submission. The program committee or reviewers are experts in the field who evaluate the papers based on their quality, significance, novelty, methodology, and other relevant criteria. They provide comments and scores for each paper.\n",
    "- Rebuttal Period: After receiving the reviews, authors are given a specific period (usually around a week) to write a rebuttal. The rebuttal is a formal response to the reviewers' comments. It allows authors to clarify misunderstandings, address concerns, and provide additional information to support their paper's quality. \n",
    "- Final Review: After receiving the rebuttals, the reviewers may reconsider their initial assessments in light of the authors' responses. Reviewers may choose to maintain or adjust their reviews and scores based on the quality and effectiveness of the author's rebuttal.\n",
    "- Final Decision: The program committee or conference organizers consider the initial reviews/scores, rebuttals, and revised reviews/scores to make a final decision on the acceptance of the papers. The decision can be acceptance, rejection, or conditional acceptance with a request for revisions.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Data\n",
    "\n",
    "- `tmp_id`: Unique identifier for each paper in the format \"P{number}\".\n",
    "- `status`: Accept or Reject.\n",
    "- `submission_type`: Short vs. Long (papers can have different lengths). We do not use this column in this homework. \n",
    "- `track`: Track to which the paper was submitted, broadly speaking, the \"topic\" of the paper.\n",
    "- `scores_before`: Scores received before rebuttal. This is a nested JSON with many fields, but we will use only the \"overall\" score for the homework. \n",
    "- `scores_after`: Scores received after rebuttal. This is a nested JSON with many fields, but we will use only the \"overall\" score for the homework.\n",
    "- `had_rebuttal`: True or False.\n",
    "\n",
    "\n",
    "Note that: \n",
    " - reviews are assigned numbers, e.g., \"2\";\n",
    " - papers can have different numbers of reviews;\n",
    " - review numbers are arbitrary, e.g., `P1` in the dataframe has two reviews numbered \"2\" and \"3\" (but no review \"1\").\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28074a9c",
   "metadata": {},
   "source": [
    "## Task 1 (10 pts): Get to Know Your Data\n",
    "\n",
    "As a good data scientist, you first load the data and perform some small sanity checks on it.\n",
    "\n",
    "- You are expected to continuously alter your dataframe as you complete the tasks. E.g., if you are asked to filter the data in a specific task, continue using the filtered dataset in the subsequent tasks.\n",
    "- When we tell you to \"print the dataframe,\" make sure you print it in a way that shows the total number of rows and columns in it (`display(df)` should suffice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmp_id</th>\n",
       "      <th>status</th>\n",
       "      <th>submission_type</th>\n",
       "      <th>track</th>\n",
       "      <th>scores_before</th>\n",
       "      <th>scores_after</th>\n",
       "      <th>had_rebuttal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P2</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Question Answering</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P3</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Short</td>\n",
       "      <td>Multidisciplinary and Area Chair COI</td>\n",
       "      <td>{'1': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P4</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P5</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Document Analysis</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>P1541</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Textual Inference and Other Areas of Semantics</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>P1542</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>P1543</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>P1544</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>P1545</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Information Extraction and Text Mining</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1538 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tmp_id  status submission_type  \\\n",
       "0        P1  Reject            Long   \n",
       "1        P2  Reject            Long   \n",
       "2        P3  Accept           Short   \n",
       "3        P4  Reject           Short   \n",
       "4        P5  Reject            Long   \n",
       "...     ...     ...             ...   \n",
       "1540  P1541  Reject           Short   \n",
       "1541  P1542  Reject            Long   \n",
       "1542  P1543  Reject            Long   \n",
       "1543  P1544  Reject           Short   \n",
       "1544  P1545  Reject           Short   \n",
       "\n",
       "                                               track  \\\n",
       "0                                   Machine Learning   \n",
       "1                                 Question Answering   \n",
       "2               Multidisciplinary and Area Chair COI   \n",
       "3                                   Machine Learning   \n",
       "4                                  Document Analysis   \n",
       "...                                              ...   \n",
       "1540  Textual Inference and Other Areas of Semantics   \n",
       "1541                                Machine Learning   \n",
       "1542                                Machine Learning   \n",
       "1543                                    Social Media   \n",
       "1544          Information Extraction and Text Mining   \n",
       "\n",
       "                                          scores_before  \\\n",
       "0     {'2': {'scores': {'originality': 2, 'soundness...   \n",
       "1     {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "2     {'1': {'scores': {'originality': 4, 'soundness...   \n",
       "3     {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "4     {'2': {'scores': {'originality': 2, 'soundness...   \n",
       "...                                                 ...   \n",
       "1540  {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "1541  {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "1542  {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "1543  {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "1544  {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "\n",
       "                                           scores_after  had_rebuttal  \n",
       "0     {'2': {'scores': {'originality': 2, 'soundness...          True  \n",
       "1     {'1': {'scores': {'originality': 2, 'soundness...          True  \n",
       "2     {'1': {'scores': {'originality': 4, 'soundness...          True  \n",
       "3     {'1': {'scores': {'originality': 2, 'soundness...          True  \n",
       "4     {'2': {'scores': {'originality': 2, 'soundness...          True  \n",
       "...                                                 ...           ...  \n",
       "1540  {'1': {'scores': {'originality': 2, 'soundness...          True  \n",
       "1541  {'1': {'scores': {'originality': 2, 'soundness...         False  \n",
       "1542  {'1': {'scores': {'originality': 3, 'soundness...          True  \n",
       "1543  {'1': {'scores': {'originality': 2, 'soundness...         False  \n",
       "1544  {'1': {'scores': {'originality': 3, 'soundness...          True  \n",
       "\n",
       "[1538 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data from the JSON file\n",
    "acl_reviews_df = pd.read_json('./data/acl18_v1_numerical_final.json')\n",
    "\n",
    "# Display the first few rows of the dataframe to understand its structure\n",
    "display(acl_reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'2': {'scores': {'originality': 2,\n",
       "    'soundness_correctness': 4,\n",
       "    'substance': 4,\n",
       "    'replicability': 4,\n",
       "    'meaningful_comparison': 4,\n",
       "    'readability': 4,\n",
       "    'overall_score': 2},\n",
       "   'contributions': {'nlp_tasks_applications': 'Marginal contribution',\n",
       "    'methods_algorithms': None,\n",
       "    'theoretical_algorithmic_results': None,\n",
       "    'empirical_results': None,\n",
       "    'data_resources': None,\n",
       "    'software_systems': None,\n",
       "    'evaluation_methods_metrics': None},\n",
       "   'checks': {'appropriateness': 'Appropriate',\n",
       "    'adhere_to_acl_2018_guidelines': 'Yes',\n",
       "    'adhere_to_acl_author_guidelines': 'Yes',\n",
       "    'handling_of_data_resources': None,\n",
       "    'handling_of_human_participants': None}},\n",
       "  '3': {'scores': {'originality': 4,\n",
       "    'soundness_correctness': 2,\n",
       "    'substance': 2,\n",
       "    'replicability': 4,\n",
       "    'meaningful_comparison': 2,\n",
       "    'readability': 3,\n",
       "    'overall_score': 3},\n",
       "   'contributions': {'nlp_tasks_applications': 'Moderate contribution',\n",
       "    'methods_algorithms': 'Moderate contribution',\n",
       "    'theoretical_algorithmic_results': None,\n",
       "    'empirical_results': 'Moderate contribution',\n",
       "    'data_resources': 'Marginal contribution',\n",
       "    'software_systems': 'Moderate contribution',\n",
       "    'evaluation_methods_metrics': None},\n",
       "   'checks': {'appropriateness': 'Appropriate',\n",
       "    'adhere_to_acl_2018_guidelines': 'Yes',\n",
       "    'adhere_to_acl_author_guidelines': 'Yes',\n",
       "    'handling_of_data_resources': 'Yes',\n",
       "    'handling_of_human_participants': None}}},\n",
       " {'2': {'scores': {'originality': 2,\n",
       "    'soundness_correctness': 4,\n",
       "    'substance': 4,\n",
       "    'replicability': 4,\n",
       "    'meaningful_comparison': 4,\n",
       "    'readability': 4,\n",
       "    'overall_score': 2},\n",
       "   'contributions': {'nlp_tasks_applications': 'Marginal contribution',\n",
       "    'methods_algorithms': None,\n",
       "    'theoretical_algorithmic_results': None,\n",
       "    'empirical_results': None,\n",
       "    'data_resources': None,\n",
       "    'software_systems': None,\n",
       "    'evaluation_methods_metrics': None},\n",
       "   'checks': {'appropriateness': 'Appropriate',\n",
       "    'adhere_to_acl_2018_guidelines': 'Yes',\n",
       "    'adhere_to_acl_author_guidelines': 'Yes',\n",
       "    'handling_of_data_resources': None,\n",
       "    'handling_of_human_participants': None}},\n",
       "  '3': {'scores': {'originality': 4,\n",
       "    'soundness_correctness': 2,\n",
       "    'substance': 2,\n",
       "    'replicability': 4,\n",
       "    'meaningful_comparison': 2,\n",
       "    'readability': 3,\n",
       "    'overall_score': 3},\n",
       "   'contributions': {'nlp_tasks_applications': 'Moderate contribution',\n",
       "    'methods_algorithms': 'Moderate contribution',\n",
       "    'theoretical_algorithmic_results': None,\n",
       "    'empirical_results': 'Moderate contribution',\n",
       "    'data_resources': 'Marginal contribution',\n",
       "    'software_systems': 'Moderate contribution',\n",
       "    'evaluation_methods_metrics': None},\n",
       "   'checks': {'appropriateness': 'Appropriate',\n",
       "    'adhere_to_acl_2018_guidelines': 'Yes',\n",
       "    'adhere_to_acl_author_guidelines': 'Yes',\n",
       "    'handling_of_data_resources': 'Yes',\n",
       "    'handling_of_human_participants': None}}})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the first few rows of 'scores_before' and 'scores_after' columns to understand their structure\n",
    "example_scores_before = acl_reviews_df['scores_before'].iloc[0]\n",
    "example_scores_after = acl_reviews_df['scores_after'].iloc[0]\n",
    "\n",
    "example_scores_before, example_scores_after\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ab063",
   "metadata": {},
   "source": [
    "**1.1** Load the dataset containing ACL reviews into memory using pandas. \n",
    "- For each paper, create rows `overall_score_before_avg` and `overall_score_after_avg` containing the average (overall) scores before and after rebuttal.\n",
    "- For each paper, create rows `overall_score_before_std` and `overall_score_after_std` containing the standard deviation of the overall scores before and after the rebuttal.\n",
    "- Print the four newly created rows for paper `P17`.\n",
    "- Print the resulting dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The `scores_{before/after}` have the following structure:\n",
    "```json\n",
    "{\n",
    "    \"reviewer_id\": {\n",
    "        \"scores\": {\n",
    "            \"originality\": value,\n",
    "            \"soundness_correctness\": value,\n",
    "            \"substance\": value,\n",
    "            \"replicability\": value,\n",
    "            \"meaningful_comparison\": value,\n",
    "            \"readability\": value,\n",
    "            \"overall_score\": value\n",
    "        },\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_avg(scores_json):\n",
    "    if scores_json is None or not scores_json:\n",
    "        return np.nan\n",
    "    \n",
    "    return np.mean([review['scores']['overall_score'] for review_id, review in scores_json.items()])\n",
    "\n",
    "def scores_std(scores_json):\n",
    "    if scores_json is None or not scores_json:\n",
    "        return np.nan\n",
    "\n",
    "    return np.std([review['scores']['overall_score'] for review_id, review in scores_json.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmp_id</th>\n",
       "      <th>status</th>\n",
       "      <th>submission_type</th>\n",
       "      <th>track</th>\n",
       "      <th>scores_before</th>\n",
       "      <th>scores_after</th>\n",
       "      <th>had_rebuttal</th>\n",
       "      <th>overall_score_before_avg</th>\n",
       "      <th>overall_score_after_avg</th>\n",
       "      <th>overall_score_before_std</th>\n",
       "      <th>overall_score_after_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P2</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Question Answering</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.942809</td>\n",
       "      <td>0.942809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P3</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Short</td>\n",
       "      <td>Multidisciplinary and Area Chair COI</td>\n",
       "      <td>{'1': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.471405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P4</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>1.247219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P5</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Document Analysis</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tmp_id  status submission_type                                 track  \\\n",
       "0     P1  Reject            Long                      Machine Learning   \n",
       "1     P2  Reject            Long                    Question Answering   \n",
       "2     P3  Accept           Short  Multidisciplinary and Area Chair COI   \n",
       "3     P4  Reject           Short                      Machine Learning   \n",
       "4     P5  Reject            Long                     Document Analysis   \n",
       "\n",
       "                                       scores_before  \\\n",
       "0  {'2': {'scores': {'originality': 2, 'soundness...   \n",
       "1  {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "2  {'1': {'scores': {'originality': 4, 'soundness...   \n",
       "3  {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "4  {'2': {'scores': {'originality': 2, 'soundness...   \n",
       "\n",
       "                                        scores_after  had_rebuttal  \\\n",
       "0  {'2': {'scores': {'originality': 2, 'soundness...          True   \n",
       "1  {'1': {'scores': {'originality': 2, 'soundness...          True   \n",
       "2  {'1': {'scores': {'originality': 4, 'soundness...          True   \n",
       "3  {'1': {'scores': {'originality': 2, 'soundness...          True   \n",
       "4  {'2': {'scores': {'originality': 2, 'soundness...          True   \n",
       "\n",
       "   overall_score_before_avg  overall_score_after_avg  \\\n",
       "0                  2.500000                 2.500000   \n",
       "1                  3.333333                 3.333333   \n",
       "2                  4.666667                 4.666667   \n",
       "3                  3.000000                 2.666667   \n",
       "4                  3.000000                 2.500000   \n",
       "\n",
       "   overall_score_before_std  overall_score_after_std  \n",
       "0                  0.500000                 0.500000  \n",
       "1                  0.942809                 0.942809  \n",
       "2                  0.471405                 0.471405  \n",
       "3                  0.816497                 1.247219  \n",
       "4                  0.000000                 0.500000  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acl_reviews_df['overall_score_before_avg']  = acl_reviews_df['scores_before'].apply(scores_avg)\n",
    "acl_reviews_df['overall_score_after_avg'] = acl_reviews_df['scores_after'].apply(scores_avg)\n",
    "acl_reviews_df['overall_score_before_std'] = acl_reviews_df['scores_before'].apply(scores_std)\n",
    "acl_reviews_df['overall_score_after_std'] = acl_reviews_df['scores_after'].apply(scores_std)\n",
    "acl_reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmp_id</th>\n",
       "      <th>status</th>\n",
       "      <th>submission_type</th>\n",
       "      <th>track</th>\n",
       "      <th>scores_before</th>\n",
       "      <th>scores_after</th>\n",
       "      <th>had_rebuttal</th>\n",
       "      <th>overall_score_before_avg</th>\n",
       "      <th>overall_score_after_avg</th>\n",
       "      <th>overall_score_before_std</th>\n",
       "      <th>overall_score_after_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>P17</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Long</td>\n",
       "      <td>Dialogue and Interactive Systems</td>\n",
       "      <td>{'1': {'scores': {'originality': 5, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 5, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tmp_id  status submission_type                             track  \\\n",
       "16    P17  Accept            Long  Dialogue and Interactive Systems   \n",
       "\n",
       "                                        scores_before  \\\n",
       "16  {'1': {'scores': {'originality': 5, 'soundness...   \n",
       "\n",
       "                                         scores_after  had_rebuttal  \\\n",
       "16  {'1': {'scores': {'originality': 5, 'soundness...          True   \n",
       "\n",
       "    overall_score_before_avg  overall_score_after_avg  \\\n",
       "16                       4.5                      4.5   \n",
       "\n",
       "    overall_score_before_std  overall_score_after_std  \n",
       "16                       0.5                      0.5  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acl_reviews_df[acl_reviews_df['tmp_id'] == 'P17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmp_id</th>\n",
       "      <th>status</th>\n",
       "      <th>submission_type</th>\n",
       "      <th>track</th>\n",
       "      <th>scores_before</th>\n",
       "      <th>scores_after</th>\n",
       "      <th>had_rebuttal</th>\n",
       "      <th>overall_score_before_avg</th>\n",
       "      <th>overall_score_after_avg</th>\n",
       "      <th>overall_score_before_std</th>\n",
       "      <th>overall_score_after_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P2</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Question Answering</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.942809</td>\n",
       "      <td>0.942809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P3</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Short</td>\n",
       "      <td>Multidisciplinary and Area Chair COI</td>\n",
       "      <td>{'1': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.471405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P4</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>1.247219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P5</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Document Analysis</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>P1541</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Textual Inference and Other Areas of Semantics</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.471405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>P1542</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.816497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>P1543</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.942809</td>\n",
       "      <td>0.942809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>P1544</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>P1545</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Information Extraction and Text Mining</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.816497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1538 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tmp_id  status submission_type  \\\n",
       "0        P1  Reject            Long   \n",
       "1        P2  Reject            Long   \n",
       "2        P3  Accept           Short   \n",
       "3        P4  Reject           Short   \n",
       "4        P5  Reject            Long   \n",
       "...     ...     ...             ...   \n",
       "1540  P1541  Reject           Short   \n",
       "1541  P1542  Reject            Long   \n",
       "1542  P1543  Reject            Long   \n",
       "1543  P1544  Reject           Short   \n",
       "1544  P1545  Reject           Short   \n",
       "\n",
       "                                               track  \\\n",
       "0                                   Machine Learning   \n",
       "1                                 Question Answering   \n",
       "2               Multidisciplinary and Area Chair COI   \n",
       "3                                   Machine Learning   \n",
       "4                                  Document Analysis   \n",
       "...                                              ...   \n",
       "1540  Textual Inference and Other Areas of Semantics   \n",
       "1541                                Machine Learning   \n",
       "1542                                Machine Learning   \n",
       "1543                                    Social Media   \n",
       "1544          Information Extraction and Text Mining   \n",
       "\n",
       "                                          scores_before  \\\n",
       "0     {'2': {'scores': {'originality': 2, 'soundness...   \n",
       "1     {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "2     {'1': {'scores': {'originality': 4, 'soundness...   \n",
       "3     {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "4     {'2': {'scores': {'originality': 2, 'soundness...   \n",
       "...                                                 ...   \n",
       "1540  {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "1541  {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "1542  {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "1543  {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "1544  {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "\n",
       "                                           scores_after  had_rebuttal  \\\n",
       "0     {'2': {'scores': {'originality': 2, 'soundness...          True   \n",
       "1     {'1': {'scores': {'originality': 2, 'soundness...          True   \n",
       "2     {'1': {'scores': {'originality': 4, 'soundness...          True   \n",
       "3     {'1': {'scores': {'originality': 2, 'soundness...          True   \n",
       "4     {'2': {'scores': {'originality': 2, 'soundness...          True   \n",
       "...                                                 ...           ...   \n",
       "1540  {'1': {'scores': {'originality': 2, 'soundness...          True   \n",
       "1541  {'1': {'scores': {'originality': 2, 'soundness...         False   \n",
       "1542  {'1': {'scores': {'originality': 3, 'soundness...          True   \n",
       "1543  {'1': {'scores': {'originality': 2, 'soundness...         False   \n",
       "1544  {'1': {'scores': {'originality': 3, 'soundness...          True   \n",
       "\n",
       "      overall_score_before_avg  overall_score_after_avg  \\\n",
       "0                     2.500000                 2.500000   \n",
       "1                     3.333333                 3.333333   \n",
       "2                     4.666667                 4.666667   \n",
       "3                     3.000000                 2.666667   \n",
       "4                     3.000000                 2.500000   \n",
       "...                        ...                      ...   \n",
       "1540                  2.333333                 2.333333   \n",
       "1541                  2.000000                 2.000000   \n",
       "1542                  2.666667                 2.666667   \n",
       "1543                  2.000000                 2.000000   \n",
       "1544                  3.000000                 3.000000   \n",
       "\n",
       "      overall_score_before_std  overall_score_after_std  \n",
       "0                     0.500000                 0.500000  \n",
       "1                     0.942809                 0.942809  \n",
       "2                     0.471405                 0.471405  \n",
       "3                     0.816497                 1.247219  \n",
       "4                     0.000000                 0.500000  \n",
       "...                        ...                      ...  \n",
       "1540                  0.471405                 0.471405  \n",
       "1541                  0.816497                 0.816497  \n",
       "1542                  0.942809                 0.942809  \n",
       "1543                  0.000000                 0.000000  \n",
       "1544                  0.816497                 0.816497  \n",
       "\n",
       "[1538 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(acl_reviews_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0075ebff",
   "metadata": {},
   "source": [
    "**1.2** Create a single plot with 14 inches of width and 4 inches of height. The plot should contain two panels: \n",
    "- **Panel A**: The distribution of `overall_score_before_avg` for papers that were accepted and papers that were rejected.\n",
    "- **Panel B**: The distribution of `overall_score_before_avg` for papers that had rebuttals vs. papers that did not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e741806e48>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,4), ncols=2, nrows=1, sharey=True)\n",
    "\n",
    "rejected_papers = acl_reviews_df[acl_reviews_df['status'] == 'Reject']\n",
    "accepted_papers = acl_reviews_df[acl_reviews_df['status'] == 'Accept']\n",
    "\n",
    "rebuttal_papers = acl_reviews_df[acl_reviews_df['had_rebuttal'] == True]\n",
    "no_rebuttal_papers = acl_reviews_df[acl_reviews_df['had_rebuttal'] == False]\n",
    "\n",
    "sns.histplot(rejected_papers['overall_score_before_avg'], kde=True, ax=ax[0], label='Rejected', alpha=0.6, color='red')\n",
    "sns.histplot(accepted_papers['overall_score_before_avg'], kde=True, ax=ax[0], label='Accepted', alpha=0.6, color='black')\n",
    "\n",
    "ax[0].set_title('Panel A: Avg Scores Before Rebuttal by Paper Status')\n",
    "ax[0].set_xlabel('Average score before rebuttal')\n",
    "ax[0].legend()\n",
    "\n",
    "\n",
    "sns.histplot(rebuttal_papers['overall_score_after_avg'], kde=True, ax=ax[1], label='Rebuttal', alpha=0.6, color='blue')\n",
    "sns.histplot(no_rebuttal_papers['overall_score_after_avg'], kde=True, ax=ax[1], label='No Rebuttal', alpha=0.6, color='orange')\n",
    "\n",
    "ax[1].set_title('Average scores after rebuttal')\n",
    "ax[1].legend(['Rebuttal', 'No rebuttal'])\n",
    "ax[1].set_title('Panel B: Avg Scores Before Rebuttal by Rebuttal Status')\n",
    "ax[1].set_xlabel('Average Score Before Rebuttal')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea160c7",
   "metadata": {},
   "source": [
    "**1.3** **/Discuss/:** If you know a paper had a rebuttal, is it more or less likely that it was accepted? Does this mean that rebuttals help papers get accepted? Explain why or why not, providing a concrete example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Before answering this question we need to consider the following two factors **Correlation vs Causation** and **Selection Bias**:\n",
    "\n",
    "- **Correlation vs Causation**: Knowing whether a paper had a rebuttal and was accepted, does not necessarily imply that the rebuttal caused the paper to be accepted. It is possible that the papers with rebuttals are more likely to be accepted but that might be due to other factors such as the quality of the paper (which increases the probability of acceptance and rebuttals $\\rightarrow$ _third-cause fallacy_).\n",
    "\n",
    "- **Selection Bias**: Papers that have rebuttabls might have been different in some way from the ones that didn't (e.g. different quality, controversial topic, etc.). Without controlling all the possible confounding factors, we cannot conclude that the rebuttals caused the paper to be accepted.\n",
    "\n",
    "So in cocnlusion there may be some correlation between papers with rebuttals and papers that got accepted, but we cannot further analysis is needed in order to make more confident conclusions.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87836f37",
   "metadata": {},
   "source": [
    "**1.4** Print the percentage of rebuttals per track in the conference (defined by the `track` column). \n",
    "\n",
    "**/Discuss:/** Using \"the logic\" of hypothesis testing (see slide 29 of Lecture 4), how would you devise a statistical test to refute the following null hypothesis: all tracks have the same fraction of papers with rebuttals. Your statistical test should consider all categories at once, rather than comparing the fraction of rebuttals between pairs of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>had_rebuttal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dialogue and Interactive Systems</td>\n",
       "      <td>0.775281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Discourse and Pragmatics</td>\n",
       "      <td>0.804348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Document Analysis</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Generation</td>\n",
       "      <td>0.779661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Information Extraction and Text Mining</td>\n",
       "      <td>0.768362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Linguistic Theories Cognitive Modeling and Psy...</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>0.808696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Machine Translation</td>\n",
       "      <td>0.820755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Multidisciplinary and Area Chair COI</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Multilinguality</td>\n",
       "      <td>0.806452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Phonology Morphology and Word Segmentation</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Question Answering</td>\n",
       "      <td>0.728395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Resources and Evaluation</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sentence-level semantics</td>\n",
       "      <td>0.788889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sentiment Analysis and Argument Mining</td>\n",
       "      <td>0.788235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Social Media</td>\n",
       "      <td>0.737705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>0.745098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Tagging Chunking Syntax and Parsing</td>\n",
       "      <td>0.770492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Textual Inference and Other Areas of Semantics</td>\n",
       "      <td>0.771930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Vision Robotics Multimodal Grounding and Speech</td>\n",
       "      <td>0.811321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Word-level Semantics</td>\n",
       "      <td>0.860759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                track  had_rebuttal\n",
       "0                    Dialogue and Interactive Systems      0.775281\n",
       "1                            Discourse and Pragmatics      0.804348\n",
       "2                                   Document Analysis      0.730000\n",
       "3                                          Generation      0.779661\n",
       "4              Information Extraction and Text Mining      0.768362\n",
       "5   Linguistic Theories Cognitive Modeling and Psy...      0.750000\n",
       "6                                    Machine Learning      0.808696\n",
       "7                                 Machine Translation      0.820755\n",
       "8                Multidisciplinary and Area Chair COI      0.680000\n",
       "9                                     Multilinguality      0.806452\n",
       "10         Phonology Morphology and Word Segmentation      0.851852\n",
       "11                                 Question Answering      0.728395\n",
       "12                           Resources and Evaluation      0.732394\n",
       "13                           Sentence-level semantics      0.788889\n",
       "14             Sentiment Analysis and Argument Mining      0.788235\n",
       "15                                       Social Media      0.737705\n",
       "16                                      Summarization      0.745098\n",
       "17                Tagging Chunking Syntax and Parsing      0.770492\n",
       "18     Textual Inference and Other Areas of Semantics      0.771930\n",
       "19    Vision Robotics Multimodal Grounding and Speech      0.811321\n",
       "20                               Word-level Semantics      0.860759"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rebutals_per_track = acl_reviews_df.groupby('track')['had_rebuttal'].apply(lambda x: np.sum(x) / len(x)).reset_index()\n",
    "display(rebutals_per_track)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**:\n",
    "\n",
    "To verify $H_0 = \\{\\text{all tracks have the same fraction of papers with rebuttals}\\}$ we can use a $\\chi^2$ test. Which is fit for categorical data and can be used to determine whether there is a significant association between two categorical variables. In this case `track` and `had_rebuttal`.\n",
    "\n",
    "We can define it in the following way:\n",
    ">$H_0$: The fraction of rebuttals is the same for all tracks.\n",
    "\n",
    ">$H_1$: The fraction of rebuttals is not the same for all tracks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50275647",
   "metadata": {},
   "source": [
    "## Task 2 (10pts): Prediction\n",
    "\n",
    "You decide to investigate further the effect of rebuttals on acceptance using your machine learning skills."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578baafa",
   "metadata": {},
   "source": [
    "\n",
    "**2.1** For each possible value in the `track` column, create a new column called {track}-onehot (e.g., for track=Generation, create Generation-onehot). Collectively, these new columns should \"one hot-encode\" the track column---for instance, if for a given paper the `track` column is filled with the value \"Generation\", the Generation-onehot column should equal 1 and all other {track}-onehot columns should equal 0. \n",
    "\n",
    "Print the column names of the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmp_id</th>\n",
       "      <th>status</th>\n",
       "      <th>submission_type</th>\n",
       "      <th>track</th>\n",
       "      <th>scores_before</th>\n",
       "      <th>scores_after</th>\n",
       "      <th>had_rebuttal</th>\n",
       "      <th>overall_score_before_avg</th>\n",
       "      <th>overall_score_after_avg</th>\n",
       "      <th>overall_score_before_std</th>\n",
       "      <th>overall_score_after_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P2</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Question Answering</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.942809</td>\n",
       "      <td>0.942809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P3</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Short</td>\n",
       "      <td>Multidisciplinary and Area Chair COI</td>\n",
       "      <td>{'1': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.471405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P4</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>1.247219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P5</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Document Analysis</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>P1541</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Textual Inference and Other Areas of Semantics</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.471405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>P1542</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.816497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>P1543</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.942809</td>\n",
       "      <td>0.942809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>P1544</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>P1545</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Information Extraction and Text Mining</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.816497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1538 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tmp_id  status submission_type  \\\n",
       "0        P1  Reject            Long   \n",
       "1        P2  Reject            Long   \n",
       "2        P3  Accept           Short   \n",
       "3        P4  Reject           Short   \n",
       "4        P5  Reject            Long   \n",
       "...     ...     ...             ...   \n",
       "1540  P1541  Reject           Short   \n",
       "1541  P1542  Reject            Long   \n",
       "1542  P1543  Reject            Long   \n",
       "1543  P1544  Reject           Short   \n",
       "1544  P1545  Reject           Short   \n",
       "\n",
       "                                               track  \\\n",
       "0                                   Machine Learning   \n",
       "1                                 Question Answering   \n",
       "2               Multidisciplinary and Area Chair COI   \n",
       "3                                   Machine Learning   \n",
       "4                                  Document Analysis   \n",
       "...                                              ...   \n",
       "1540  Textual Inference and Other Areas of Semantics   \n",
       "1541                                Machine Learning   \n",
       "1542                                Machine Learning   \n",
       "1543                                    Social Media   \n",
       "1544          Information Extraction and Text Mining   \n",
       "\n",
       "                                          scores_before  \\\n",
       "0     {'2': {'scores': {'originality': 2, 'soundness...   \n",
       "1     {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "2     {'1': {'scores': {'originality': 4, 'soundness...   \n",
       "3     {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "4     {'2': {'scores': {'originality': 2, 'soundness...   \n",
       "...                                                 ...   \n",
       "1540  {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "1541  {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "1542  {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "1543  {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "1544  {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "\n",
       "                                           scores_after  had_rebuttal  \\\n",
       "0     {'2': {'scores': {'originality': 2, 'soundness...          True   \n",
       "1     {'1': {'scores': {'originality': 2, 'soundness...          True   \n",
       "2     {'1': {'scores': {'originality': 4, 'soundness...          True   \n",
       "3     {'1': {'scores': {'originality': 2, 'soundness...          True   \n",
       "4     {'2': {'scores': {'originality': 2, 'soundness...          True   \n",
       "...                                                 ...           ...   \n",
       "1540  {'1': {'scores': {'originality': 2, 'soundness...          True   \n",
       "1541  {'1': {'scores': {'originality': 2, 'soundness...         False   \n",
       "1542  {'1': {'scores': {'originality': 3, 'soundness...          True   \n",
       "1543  {'1': {'scores': {'originality': 2, 'soundness...         False   \n",
       "1544  {'1': {'scores': {'originality': 3, 'soundness...          True   \n",
       "\n",
       "      overall_score_before_avg  overall_score_after_avg  \\\n",
       "0                     2.500000                 2.500000   \n",
       "1                     3.333333                 3.333333   \n",
       "2                     4.666667                 4.666667   \n",
       "3                     3.000000                 2.666667   \n",
       "4                     3.000000                 2.500000   \n",
       "...                        ...                      ...   \n",
       "1540                  2.333333                 2.333333   \n",
       "1541                  2.000000                 2.000000   \n",
       "1542                  2.666667                 2.666667   \n",
       "1543                  2.000000                 2.000000   \n",
       "1544                  3.000000                 3.000000   \n",
       "\n",
       "      overall_score_before_std  overall_score_after_std  \n",
       "0                     0.500000                 0.500000  \n",
       "1                     0.942809                 0.942809  \n",
       "2                     0.471405                 0.471405  \n",
       "3                     0.816497                 1.247219  \n",
       "4                     0.000000                 0.500000  \n",
       "...                        ...                      ...  \n",
       "1540                  0.471405                 0.471405  \n",
       "1541                  0.816497                 0.816497  \n",
       "1542                  0.942809                 0.942809  \n",
       "1543                  0.000000                 0.000000  \n",
       "1544                  0.816497                 0.816497  \n",
       "\n",
       "[1538 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tracks = acl_reviews_df['track'].unique()\n",
    "acl_reviews_df_onehot = acl_reviews_df.copy()\n",
    "\n",
    "for track in tracks:\n",
    "    acl_reviews_df_onehot[f'{track}-onehot'] = acl_reviews_df_onehot['track'].apply(lambda x: 1 if x == track else 0)\n",
    "\n",
    "display(acl_reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the genres and countries variable\n",
    "#acl_reviews_df_onehot = pd.get_dummies(acl_reviews_df, columns=['track'])\n",
    "#suffix = '_onehot'\n",
    "#display(acl_reviews_df_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aa41ea",
   "metadata": {},
   "source": [
    "\n",
    "**2.2** Create a column `had_rebuttal_int`, which equals 1 if the paper had a rebuttal, and 0 otherwise, and a column `accepted_int`, which equals 1 if the paper was accepted, and 0 otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmp_id</th>\n",
       "      <th>status</th>\n",
       "      <th>submission_type</th>\n",
       "      <th>track</th>\n",
       "      <th>scores_before</th>\n",
       "      <th>scores_after</th>\n",
       "      <th>had_rebuttal</th>\n",
       "      <th>overall_score_before_avg</th>\n",
       "      <th>overall_score_after_avg</th>\n",
       "      <th>overall_score_before_std</th>\n",
       "      <th>...</th>\n",
       "      <th>Vision Robotics Multimodal Grounding and Speech-onehot</th>\n",
       "      <th>Resources and Evaluation-onehot</th>\n",
       "      <th>Sentiment Analysis and Argument Mining-onehot</th>\n",
       "      <th>Summarization-onehot</th>\n",
       "      <th>Discourse and Pragmatics-onehot</th>\n",
       "      <th>Generation-onehot</th>\n",
       "      <th>Multilinguality-onehot</th>\n",
       "      <th>Social Media-onehot</th>\n",
       "      <th>had_rebuttal_int</th>\n",
       "      <th>accepted_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P2</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Question Answering</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.942809</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P3</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Short</td>\n",
       "      <td>Multidisciplinary and Area Chair COI</td>\n",
       "      <td>{'1': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P4</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P5</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Document Analysis</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  tmp_id  status submission_type                                 track  \\\n",
       "0     P1  Reject            Long                      Machine Learning   \n",
       "1     P2  Reject            Long                    Question Answering   \n",
       "2     P3  Accept           Short  Multidisciplinary and Area Chair COI   \n",
       "3     P4  Reject           Short                      Machine Learning   \n",
       "4     P5  Reject            Long                     Document Analysis   \n",
       "\n",
       "                                       scores_before  \\\n",
       "0  {'2': {'scores': {'originality': 2, 'soundness...   \n",
       "1  {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "2  {'1': {'scores': {'originality': 4, 'soundness...   \n",
       "3  {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "4  {'2': {'scores': {'originality': 2, 'soundness...   \n",
       "\n",
       "                                        scores_after  had_rebuttal  \\\n",
       "0  {'2': {'scores': {'originality': 2, 'soundness...          True   \n",
       "1  {'1': {'scores': {'originality': 2, 'soundness...          True   \n",
       "2  {'1': {'scores': {'originality': 4, 'soundness...          True   \n",
       "3  {'1': {'scores': {'originality': 2, 'soundness...          True   \n",
       "4  {'2': {'scores': {'originality': 2, 'soundness...          True   \n",
       "\n",
       "   overall_score_before_avg  overall_score_after_avg  \\\n",
       "0                  2.500000                 2.500000   \n",
       "1                  3.333333                 3.333333   \n",
       "2                  4.666667                 4.666667   \n",
       "3                  3.000000                 2.666667   \n",
       "4                  3.000000                 2.500000   \n",
       "\n",
       "   overall_score_before_std  ...  \\\n",
       "0                  0.500000  ...   \n",
       "1                  0.942809  ...   \n",
       "2                  0.471405  ...   \n",
       "3                  0.816497  ...   \n",
       "4                  0.000000  ...   \n",
       "\n",
       "   Vision Robotics Multimodal Grounding and Speech-onehot  \\\n",
       "0                                                  0        \n",
       "1                                                  0        \n",
       "2                                                  0        \n",
       "3                                                  0        \n",
       "4                                                  0        \n",
       "\n",
       "   Resources and Evaluation-onehot  \\\n",
       "0                                0   \n",
       "1                                0   \n",
       "2                                0   \n",
       "3                                0   \n",
       "4                                0   \n",
       "\n",
       "   Sentiment Analysis and Argument Mining-onehot  Summarization-onehot  \\\n",
       "0                                              0                     0   \n",
       "1                                              0                     0   \n",
       "2                                              0                     0   \n",
       "3                                              0                     0   \n",
       "4                                              0                     0   \n",
       "\n",
       "   Discourse and Pragmatics-onehot  Generation-onehot  Multilinguality-onehot  \\\n",
       "0                                0                  0                       0   \n",
       "1                                0                  0                       0   \n",
       "2                                0                  0                       0   \n",
       "3                                0                  0                       0   \n",
       "4                                0                  0                       0   \n",
       "\n",
       "   Social Media-onehot  had_rebuttal_int  accepted_int  \n",
       "0                    0                 1             0  \n",
       "1                    0                 1             0  \n",
       "2                    0                 1             1  \n",
       "3                    0                 1             0  \n",
       "4                    0                 1             0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acl_reviews_df_onehot['had_rebuttal_int'] = acl_reviews_df_onehot['had_rebuttal'].apply(lambda x: 1 if x else 0)\n",
    "acl_reviews_df_onehot['accepted_int'] = acl_reviews_df_onehot['status'].apply(lambda x: 1 if x == 'Accept' else 0)\n",
    "acl_reviews_df_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5806400",
   "metadata": {},
   "source": [
    "**2.3** Create a function `numpy_helper(df, cols)` to obtain a numpy.array out of your dataframe. The function should receive a dataframe `df` with N rows and a list of M columns `cols`, and should return a `np.array` of dimension `(NxM)` cast as a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_helper(df, cols):\n",
    "    '''\n",
    "    Obtain numpy.array out of the given df.\n",
    "    df: dataframe of size (n, m)\n",
    "    cols: list of column names of size p < m\n",
    "    '''\n",
    "    return df[cols].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dad455",
   "metadata": {},
   "source": [
    "\n",
    "**2.4**\n",
    "Create:\n",
    "- an array of features X containing all track one-hot features, as well as the `overall_score_before_avg`,`overall_score_before_std`, and `had_rebuttal_int`;\n",
    "- an array of outcomes y containing `accepted_int`. \n",
    "\n",
    "\n",
    "Print the shapes of both X and y (e.g., `X.shape`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (1538, 24)\n",
      "y.shape: (1538, 1)\n"
     ]
    }
   ],
   "source": [
    "tracks = acl_reviews_df_onehot['track'].unique()\n",
    "cols = [f'{track}-onehot' for track in tracks]\n",
    "cols += ['overall_score_before_avg', 'overall_score_before_std', 'had_rebuttal_int']\n",
    "\n",
    "X = numpy_helper(acl_reviews_df_onehot, cols)\n",
    "y = numpy_helper(acl_reviews_df_onehot, ['accepted_int'])\n",
    "\n",
    "print(f'X.shape: {X.shape}')\n",
    "print(f'y.shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf79a4",
   "metadata": {},
   "source": [
    "\n",
    "**2.5** Build two `GradientBoostingClassifier` models using `sklearn` using the default parameters:\n",
    "- Model 1: predicts the outcome `accepted_int` using the onehot encoded features related to track, as well as the `overall_score_before_avg`,`overall_score_before_std`.\n",
    "- Model 2:  predicts the outcome `accepted_int` using the onehot encoded features related to track, as well as the `overall_score_before_avg`,`overall_score_before_std` **and** `had_rebuttal_int`.\n",
    "\n",
    "\n",
    "For both models:\n",
    "\n",
    "- Use the `cross_validate` function from `sklearn.model_selection` to compute the average precision, recall, and accuracy across test cross validation splits.\n",
    "\n",
    "    - e.g., `cross_validate(clf, X, y, cv=30, scoring=('accuracy', 'precision', 'recall'))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1\n",
    "# one hot + scores before and after (no rebuttal)\n",
    "cols_1 = [f'{track}-onehot' for track in tracks]\n",
    "cols_1 += ['overall_score_before_avg', 'overall_score_before_std']\n",
    "X_1 = numpy_helper(acl_reviews_df_onehot, cols_1)\n",
    "\n",
    "# Model 2\n",
    "# one hot + scores before and after + rebuttal\n",
    "cols_2 = cols_1 + ['had_rebuttal_int']\n",
    "X_2 = numpy_helper(acl_reviews_df_onehot, cols_2)\n",
    "\n",
    "# Define models\n",
    "model_1 = GradientBoostingClassifier()\n",
    "model_2 = GradientBoostingClassifier()\n",
    "\n",
    "# Cross validate\n",
    "cv_results_1 = cross_validate(model_1, X_1, y.ravel(), cv=30, scoring=('accuracy', 'precision', 'recall'))\n",
    "cv_results_2 = cross_validate(model_2, X_2, y.ravel(), cv=30, scoring=('accuracy', 'precision', 'recall'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abba6d4",
   "metadata": {},
   "source": [
    "\n",
    "**2.6** Determine whether the difference in accuracy of the two models is statistically significant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 1: 0.8373303167420816\n",
      "Accuracy of model 2: 0.8386500754147814\n",
      "p-value: 0.48357829299551125\n"
     ]
    }
   ],
   "source": [
    "acc_model_1 = cv_results_1['test_accuracy']\n",
    "acc_model_2 = cv_results_2['test_accuracy']\n",
    "\n",
    "\n",
    "t_stat, p_val = stats.ttest_rel(acc_model_1, acc_model_2)\n",
    "\n",
    "print(f'Accuracy of model 1: {np.mean(acc_model_1)}')\n",
    "print(f'Accuracy of model 2: {np.mean(acc_model_2)}')\n",
    "print(f'p-value: {p_val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9518f2f6",
   "metadata": {},
   "source": [
    "**2.7** Contrast the results obtained in **2.6** with what you observed in **Task 1**. What advantage did the analyses in **2.6** have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "- The p-value (0.48) suggests that there is no statistically significant difference between the two models' accuracies. This indicates that including the had_rebuttal_int feature does not significantly impact the model's ability to predict paper acceptance.\n",
    "- The close mean accuracies of both models further support this conclusion. The rebuttal feature does not seem to be a deciding factor in predicting acceptance when considering other features like the track and initial scores.\n",
    "- This finding contrasts with the observations from Task 1, where the rebuttal process appeared to introduce variability in scores. However, when it comes to predicting acceptance, the rebuttal's impact may not be as significant as initially thought.\n",
    "- The analysis in 2.6 provides a more quantifiable and statistically sound evaluation of the rebuttal's impact compared to the descriptive and observational analysis in Task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52beb97e",
   "metadata": {},
   "source": [
    "## Task 3 (12pts): Interlude\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f56eca",
   "metadata": {},
   "source": [
    "\n",
    "**3.1** Using the formula API from `statsmodels`, estimate the following linear regression. Report the summary of the models.\n",
    "- `accepted_int ~ had_rebuttal_int`,  \n",
    "- `accepted_int ~ overall_score_after_avg`\n",
    "- `had_rebuttal_int ~ overall_score_before_avg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           accepted_int   R-squared:                       0.041\n",
      "Model:                            OLS   Adj. R-squared:                  0.041\n",
      "Method:                 Least Squares   F-statistic:                     66.22\n",
      "Date:                Tue, 28 Nov 2023   Prob (F-statistic):           8.24e-16\n",
      "Time:                        18:50:14   Log-Likelihood:                -855.16\n",
      "No. Observations:                1538   AIC:                             1714.\n",
      "Df Residuals:                    1536   BIC:                             1725.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "Intercept                    0.0838      0.023      3.693      0.000       0.039       0.128\n",
      "C(had_rebuttal_int)[T.1]     0.2098      0.026      8.138      0.000       0.159       0.260\n",
      "==============================================================================\n",
      "Omnibus:                      271.753   Durbin-Watson:                   1.920\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              324.377\n",
      "Skew:                           1.075   Prob(JB):                     3.65e-71\n",
      "Kurtosis:                       2.336   Cond. No.                         4.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#1st linear regression model\n",
    "accepted_rebuttal = smf.ols('accepted_int ~ C(had_rebuttal_int)', data = acl_reviews_df_onehot).fit()\n",
    "print(accepted_rebuttal.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           accepted_int   R-squared:                       0.548\n",
      "Model:                            OLS   Adj. R-squared:                  0.539\n",
      "Method:                 Least Squares   F-statistic:                     60.80\n",
      "Date:                Tue, 28 Nov 2023   Prob (F-statistic):          1.58e-234\n",
      "Time:                        18:50:14   Log-Likelihood:                -277.70\n",
      "No. Observations:                1538   AIC:                             617.4\n",
      "Df Residuals:                    1507   BIC:                             782.9\n",
      "Df Model:                          30                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================================================\n",
      "                                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                         1.467e-15      0.055   2.65e-14      1.000      -0.109       0.109\n",
      "C(overall_score_after_avg)[T.1.25]                6.194e-15      0.298   2.08e-14      1.000      -0.585       0.585\n",
      "C(overall_score_after_avg)[T.1.3333333333333333]  2.006e-15      0.079   2.54e-14      1.000      -0.155       0.155\n",
      "C(overall_score_after_avg)[T.1.5]                 5.993e-17      0.077   7.79e-16      1.000      -0.151       0.151\n",
      "C(overall_score_after_avg)[T.1.6666666666666667]  5.332e-16      0.074   7.23e-15      1.000      -0.145       0.145\n",
      "C(overall_score_after_avg)[T.2.0]                    0.0068      0.060      0.112      0.911      -0.112       0.125\n",
      "C(overall_score_after_avg)[T.2.25]                2.052e-15      0.157   1.31e-14      1.000      -0.307       0.307\n",
      "C(overall_score_after_avg)[T.2.3333333333333335]     0.0093      0.062      0.149      0.881      -0.113       0.131\n",
      "C(overall_score_after_avg)[T.2.5]                -3.038e-16      0.065  -4.66e-15      1.000      -0.128       0.128\n",
      "C(overall_score_after_avg)[T.2.6]                -2.033e-15      0.298  -6.82e-15      1.000      -0.585       0.585\n",
      "C(overall_score_after_avg)[T.2.6666666666666665] -1.491e-16      0.061  -2.43e-15      1.000      -0.121       0.121\n",
      "C(overall_score_after_avg)[T.2.75]               -1.044e-15      0.157  -6.67e-15      1.000      -0.307       0.307\n",
      "C(overall_score_after_avg)[T.2.8]                  7.44e-15      0.298    2.5e-14      1.000      -0.585       0.585\n",
      "C(overall_score_after_avg)[T.3.0]                    0.0402      0.059      0.680      0.496      -0.076       0.156\n",
      "C(overall_score_after_avg)[T.3.2]                    1.0000      0.298      3.356      0.001       0.415       1.585\n",
      "C(overall_score_after_avg)[T.3.25]               -1.041e-15      0.157  -6.65e-15      1.000      -0.307       0.307\n",
      "C(overall_score_after_avg)[T.3.3333333333333335]     0.0690      0.062      1.119      0.264      -0.052       0.190\n",
      "C(overall_score_after_avg)[T.3.4]                -1.678e-15      0.298  -5.63e-15      1.000      -0.585       0.585\n",
      "C(overall_score_after_avg)[T.3.5]                    0.2073      0.064      3.235      0.001       0.082       0.333\n",
      "C(overall_score_after_avg)[T.3.6666666666666665]     0.2277      0.063      3.641      0.000       0.105       0.350\n",
      "C(overall_score_after_avg)[T.3.75]                   0.3750      0.117      3.195      0.001       0.145       0.605\n",
      "C(overall_score_after_avg)[T.4.0]                    0.5566      0.059      9.453      0.000       0.441       0.672\n",
      "C(overall_score_after_avg)[T.4.2]                -4.743e-15      0.298  -1.59e-14      1.000      -0.585       0.585\n",
      "C(overall_score_after_avg)[T.4.25]                   1.0000      0.214      4.666      0.000       0.580       1.420\n",
      "C(overall_score_after_avg)[T.4.333333333333333]      0.7848      0.064     12.186      0.000       0.658       0.911\n",
      "C(overall_score_after_avg)[T.4.5]                    0.8125      0.066     12.246      0.000       0.682       0.943\n",
      "C(overall_score_after_avg)[T.4.666666666666667]      1.0000      0.070     14.305      0.000       0.863       1.137\n",
      "C(overall_score_after_avg)[T.5.0]                    0.8947      0.073     12.269      0.000       0.752       1.038\n",
      "C(overall_score_after_avg)[T.5.333333333333333]      1.0000      0.298      3.356      0.001       0.415       1.585\n",
      "C(overall_score_after_avg)[T.5.5]                    1.0000      0.298      3.356      0.001       0.415       1.585\n",
      "C(overall_score_after_avg)[T.6.0]                -1.003e-15      0.298  -3.37e-15      1.000      -0.585       0.585\n",
      "==============================================================================\n",
      "Omnibus:                      112.022   Durbin-Watson:                   1.981\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              389.167\n",
      "Skew:                           0.294   Prob(JB):                     3.12e-85\n",
      "Kurtosis:                       5.393   Cond. No.                         52.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#2nd linear regression model\n",
    "accepted_score_after = smf.ols('accepted_int ~ C(overall_score_after_avg)', data = acl_reviews_df_onehot).fit()\n",
    "print(accepted_score_after.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           accepted_int   R-squared:                       0.425\n",
      "Model:                            OLS   Adj. R-squared:                  0.415\n",
      "Method:                 Least Squares   F-statistic:                     44.70\n",
      "Date:                Tue, 28 Nov 2023   Prob (F-statistic):          1.16e-161\n",
      "Time:                        18:50:14   Log-Likelihood:                -462.09\n",
      "No. Observations:                1538   AIC:                             976.2\n",
      "Df Residuals:                    1512   BIC:                             1115.\n",
      "Df Model:                          25                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================================================\n",
      "                                                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                          2.595e-15      0.060   4.31e-14      1.000      -0.118       0.118\n",
      "C(overall_score_before_avg)[T.1.3333333333333333] -2.952e-15      0.090  -3.27e-14      1.000      -0.177       0.177\n",
      "C(overall_score_before_avg)[T.1.5]                -1.019e-15      0.086  -1.19e-14      1.000      -0.168       0.168\n",
      "C(overall_score_before_avg)[T.1.6666666666666667] -1.675e-15      0.083  -2.02e-14      1.000      -0.163       0.163\n",
      "C(overall_score_before_avg)[T.1.75]               -2.031e-15      0.335  -6.06e-15      1.000      -0.657       0.657\n",
      "C(overall_score_before_avg)[T.2.0]                    0.0342      0.066      0.518      0.604      -0.095       0.164\n",
      "C(overall_score_before_avg)[T.2.25]               -2.776e-15      0.241  -1.15e-14      1.000      -0.472       0.472\n",
      "C(overall_score_before_avg)[T.2.3333333333333335]  -1.84e-15      0.069  -2.67e-14      1.000      -0.135       0.135\n",
      "C(overall_score_before_avg)[T.2.5]                -1.448e-15      0.072  -2.01e-14      1.000      -0.141       0.141\n",
      "C(overall_score_before_avg)[T.2.6666666666666665]     0.0094      0.068      0.138      0.890      -0.124       0.143\n",
      "C(overall_score_before_avg)[T.2.75]                1.507e-15      0.175   8.59e-15      1.000      -0.344       0.344\n",
      "C(overall_score_before_avg)[T.3.0]                    0.0553      0.064      0.861      0.389      -0.071       0.181\n",
      "C(overall_score_before_avg)[T.3.2]                 1.169e-15      0.335   3.49e-15      1.000      -0.657       0.657\n",
      "C(overall_score_before_avg)[T.3.25]                   0.6667      0.200      3.341      0.001       0.275       1.058\n",
      "C(overall_score_before_avg)[T.3.3333333333333335]     0.1654      0.067      2.472      0.014       0.034       0.297\n",
      "C(overall_score_before_avg)[T.3.5]                    0.2111      0.069      3.038      0.002       0.075       0.347\n",
      "C(overall_score_before_avg)[T.3.6666666666666665]     0.2992      0.067      4.472      0.000       0.168       0.430\n",
      "C(overall_score_before_avg)[T.3.75]                   0.7500      0.175      4.275      0.000       0.406       1.094\n",
      "C(overall_score_before_avg)[T.4.0]                    0.5088      0.064      7.946      0.000       0.383       0.634\n",
      "C(overall_score_before_avg)[T.4.25]                   0.5000      0.241      2.077      0.038       0.028       0.972\n",
      "C(overall_score_before_avg)[T.4.333333333333333]      0.7742      0.073     10.562      0.000       0.630       0.918\n",
      "C(overall_score_before_avg)[T.4.5]                    0.7465      0.072     10.402      0.000       0.606       0.887\n",
      "C(overall_score_before_avg)[T.4.666666666666667]      0.9667      0.085     11.360      0.000       0.800       1.134\n",
      "C(overall_score_before_avg)[T.5.0]                    0.8571      0.082     10.453      0.000       0.696       1.018\n",
      "C(overall_score_before_avg)[T.5.5]                    1.0000      0.241      4.155      0.000       0.528       1.472\n",
      "C(overall_score_before_avg)[T.6.0]                -2.374e-15      0.335  -7.09e-15      1.000      -0.657       0.657\n",
      "==============================================================================\n",
      "Omnibus:                      100.374   Durbin-Watson:                   1.958\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              149.705\n",
      "Skew:                           0.531   Prob(JB):                     3.10e-33\n",
      "Kurtosis:                       4.099   Cond. No.                         46.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#3rd linear regression model\n",
    "accepted_score_before = smf.ols('accepted_int ~ C(overall_score_before_avg)', data = acl_reviews_df_onehot).fit()\n",
    "print(accepted_score_before.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc5e23",
   "metadata": {},
   "source": [
    "\n",
    "**3.2** **/Discuss:/** Interpret the coefficients associated with the binary independent variables in the above models. Note that independent variables are the ones on the right-handside of the equation.\n",
    "\n",
    "- e.g., in `had_rebuttal_int ~ overall_score_before_avg`, `overall_score_before_avg` is the independent variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Linear Case**: `'accept_int ~ had_rebuttal_int’`: coeff = 0.2098, R2 = 0.041, p-value = 0.000, Intercept = 0.0838. So, we have:\n",
    "    - $Acceptance = 0.0838 + 0.2098\\cdot Rebuttal$.\n",
    "    - Now, if a paper did not have a rebuttal i.e. rebuttal = 0, it means that the average acceptance was 0.0838.\n",
    "    - On the other hand, if rebuttal = 1, the average acceptance = 0.2936. Again there’s not much to interpret here. This represents the expected change in the acceptance rate for a paper that had a rebuttal compared to one that did not, holding all else constant.\n",
    "    - Note that the results indicate that linear regression is not the best fit for the data as it can predict values outside the range of 0 and 1, which is not meaningful for a binary outcome.\n",
    "    - Our p-value is less than 0.05 which means that there’s sufficient evidence to reject the null hypothesis i.e. that the rebuttal has no effect on the acceptance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaba81dc",
   "metadata": {},
   "source": [
    "\n",
    "**3.3** **/Discuss:/** describe three correlations you can draw from the previous analysis. Describe their sign (i.e., whether they are positive or negative), and whether they are statistically significant (at the .05 level of significance).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "1. **Positive Correlation between Rebuttal and Acceptance**: Indeed, the analysis shows a statistically significant positive correlation between having a rebuttal and the likelihood of acceptance. Specifically, in the logistic regression, the coefficient for `had_rebuttal_int` is 1.5138 (p-value < 0.05), indicating a strong effect. However the R-squared values in both linear (0.041) and logistic (0.04371) models suggest that other variables also play a role in determining acceptance.\n",
    "2. **Positive Correlation between Score After Rebuttal and Acceptance**: The score after rebuttal is a significant predictor of acceptance, with R-squared values indicating that a substantial proportion of variance in acceptance is explained by this variable (linear: 0.402, logistic: 0.4990). The coefficients in both models for `overall_score_after_avg` (linear: 0.2860, logistic: 3.3178) are positive and statistically significant (p-value < 0.05), highlighting the strength of this correlation.\n",
    "3. **Positive Correlation between Score Before Rebuttal and Having a Rebuttal**: The analysis reveals a positive correlation between the score before rebuttal and the likelihood of having a rebuttal. Both models show positive coefficients (linear: 0.1651, logistic: 1.0499) with statistical significance (p-value < 0.05). The R-squared values, while modest (linear: 0.135, logistic: 0.1323), still suggest a reasonable degree of variance explanation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa59821c",
   "metadata": {},
   "source": [
    "**3.4** **/Discuss:/** Is the following statement True or False? Justify. \n",
    "\n",
    "- The variable `overall_score_after_avg` explains more of the variance in `accepted_int`than the variable `overall_score_before_avg` explains of `had_rebuttal_int`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Ok, let's analyse what our $R^2$ values mean (in the logistic regressions):\n",
    "- $R^2$ for `accept_int ~ overall_score_after_avg` = 0.499\n",
    "- $R^2$ for `had_rebuttal_int ~ overall_score_before_avg` = 0.1323.\n",
    "\n",
    "Now the $R^2$ indicates the proportion of variance that is explained by our model. So, the first model explains 49.9% of the variance in the acceptance rate. On the other hand, the second model explains 13.23% of the variance in the rebuttal rate. So, in essence, the first model better explains the observed data than the second one. \n",
    "\n",
    "With this logic we can say that the staterment is **True**.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b405fb7f",
   "metadata": {},
   "source": [
    "\n",
    "**3.5** **/Discuss:/** Create a causal diagram relating the following variables:\n",
    "- \"Sa\": `overall_score_after_avg`\n",
    "- \"Sb\": `overall_score_before_avg`\n",
    "- \"Re\": `had_rebuttal_int`\n",
    "- \"Ac\": `accepted_int`\n",
    "- \"Tr\": `track`\n",
    "\n",
    "\n",
    "When unsure about whether a causal relationship exists, include it in the diagram. E.g., include the arrow corresponding to the key questions around this homework, i.e., `had_rebuttal_int`->`accepted_int`, even though you are investigating whether it exists. \n",
    "\n",
    "You may draw your diagram using text, use Sa/Sb/Re/Ac/Tr to represent the names of the variables, and simply indicate the causal links, one per line.\n",
    "\n",
    "\n",
    "Instead of drawing something like this:\n",
    "![](./dagv.jpeg)\n",
    "\n",
    "Simply write:\n",
    "\n",
    "- Tr->Sb\n",
    "- Tr->Ac\n",
    "- Tr->Re\n",
    "- Ac->Sb\n",
    "- Re->Sb\n",
    "- Sb->Sa\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Track**:\n",
    "\n",
    "Since we have not considered the potential influence of track on the other variables, we can assume it is likely it will affect all 4 of them:\n",
    "\n",
    "- Tr -> Sb: The track of a paper might influence its initial score due to varying standards or expectations across different topics.\n",
    "- Tr -> Re: Certain tracks might be more prone to debate or discussion, potentially affecting the likelihood of a rebuttal.\n",
    "- Tr -> Sa: The track could influence the final score after rebuttal if certain topics are seen as more valuable or impactful.\n",
    "- Tr -> Ac: The acceptance of a paper might be influenced by the track, possibly due to the popularity or relevance of the topic area.\n",
    "\n",
    "**Score before rebuttal**:\n",
    "- Sb -> Re: The initial score could influence whether the paper has a rebuttal judging by the positive correlation between the two variables.\n",
    "- Sb -> Sa: The initial score is probably related to the final score after rebuttal. Logically, it would be surprising to see a paper with a very low score getting a very high one after rebuttal. \n",
    "\n",
    "\n",
    "**Having a rebuttal**:\n",
    "- Re -> Sa: The purpose of a rebuttal is to address concerns and potentially improve the paper's score and improve the likelihood of acceptance.\n",
    "- Re -> Ac: We saw a positive correlation between rebuttal and acceptance. Although it could be argued that rebuttal causes an increase in score leading to an improved Sa that is the real cause of the increase in Ac, it is also possible that the rebuttal itself is a factor in the decision to accept the paper. We would have to investigate whether there are papers that had a rebuttal but did not improve their score and were still accepted.\n",
    "\n",
    "**Score after rebuttal**:\n",
    "- Sa -> Ac: The final score after rebuttal likely influences the acceptance of the paper judging from the positive correlation between the two possibly repicting revised quality and response to feedback. \n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe89c00",
   "metadata": {},
   "source": [
    "**3.6** **/Discuss:/** What is the problem of simply comparing the outcomes of papers that had rebuttals with those that did not? Give a concrete example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "What is our goal here? To assess whether our 'treatment' i.e. having a rebuttal, causally affects the outcome i.e. acceptance. The problem is that although we indeed see a positive correlation between the two, we cannot be sure that a rebuttal directly causes an increase in acceptance. Indeed, several confounders could be influencing treatment assignment (i.e. the decision to have a rebuttal). \n",
    "\n",
    "The decision to have a rebuttal may be influenced by factors like the paper's track or its initial score. Indeed, we have already observed the positive correlation between the initial score and the likelihood of having a rebuttal. Consider, for instance, a high-quality paper that is marginally rejected. The authors of such a paper might be more motivated to write a rebuttal. In this case, the rebuttal is not the cause of the increase in acceptance, as the initial score introduces selection bias in our analysis. \n",
    "\n",
    "On the other hand, different tracks may be more prone to debate or discussion, or belong to rapidly evolving fields potentially affecting the likelihood of a rebuttal. In this case, the track is influencing the decision to have a rebuttal such that we cannot account for the effect of the rebuttal itself on the acceptance.\n",
    "\n",
    "If we wanted to indeed assess the effect of the rebuttal, we could utilise methods like propensity score matching, considering the potential confounders (e.g. track, initial score or anything else), such that our 'treatmet' and 'control' groups are as similar as possible in all aspects except for the one we are interested in (i.e. the rebuttal). This way we could more accurately assess the true effect of the rebuttal.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ed68a4",
   "metadata": {},
   "source": [
    "# Task 4 (12 pts): Observational study\n",
    "\n",
    "You decide to use your observational study skills to obtain a concrete answer to the question: do rebuttals increase acceptance?\n",
    "\n",
    " **4.1** Perform exact one-to-one matching considering the `score_before_avg` and the `track` variables. Each paper that had a rebuttal (\"treatment group\") should be matched to a paper that did not have a rebuttal (\"control group\"). \n",
    "- Your matching should be optimal, i.e., the maximum amount of papers possible must be matched. \n",
    "- Print the dataframe of papers in the matched sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmp_id</th>\n",
       "      <th>status</th>\n",
       "      <th>submission_type</th>\n",
       "      <th>track</th>\n",
       "      <th>scores_before</th>\n",
       "      <th>scores_after</th>\n",
       "      <th>had_rebuttal</th>\n",
       "      <th>overall_score_before_avg</th>\n",
       "      <th>overall_score_after_avg</th>\n",
       "      <th>overall_score_before_std</th>\n",
       "      <th>overall_score_after_std</th>\n",
       "      <th>had_rebuttal_int</th>\n",
       "      <th>accepted_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P2</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Question Answering</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.942809</td>\n",
       "      <td>0.942809</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P3</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Short</td>\n",
       "      <td>Multidisciplinary and Area Chair COI</td>\n",
       "      <td>{'1': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P4</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>1.247219</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P5</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Document Analysis</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tmp_id  status submission_type                                 track  \\\n",
       "0     P1  Reject            Long                      Machine Learning   \n",
       "1     P2  Reject            Long                    Question Answering   \n",
       "2     P3  Accept           Short  Multidisciplinary and Area Chair COI   \n",
       "3     P4  Reject           Short                      Machine Learning   \n",
       "4     P5  Reject            Long                     Document Analysis   \n",
       "\n",
       "                                       scores_before  \\\n",
       "0  {'2': {'scores': {'originality': 2, 'soundness...   \n",
       "1  {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "2  {'1': {'scores': {'originality': 4, 'soundness...   \n",
       "3  {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "4  {'2': {'scores': {'originality': 2, 'soundness...   \n",
       "\n",
       "                                        scores_after  had_rebuttal  \\\n",
       "0  {'2': {'scores': {'originality': 2, 'soundness...          True   \n",
       "1  {'1': {'scores': {'originality': 2, 'soundness...          True   \n",
       "2  {'1': {'scores': {'originality': 4, 'soundness...          True   \n",
       "3  {'1': {'scores': {'originality': 2, 'soundness...          True   \n",
       "4  {'2': {'scores': {'originality': 2, 'soundness...          True   \n",
       "\n",
       "   overall_score_before_avg  overall_score_after_avg  \\\n",
       "0                  2.500000                 2.500000   \n",
       "1                  3.333333                 3.333333   \n",
       "2                  4.666667                 4.666667   \n",
       "3                  3.000000                 2.666667   \n",
       "4                  3.000000                 2.500000   \n",
       "\n",
       "   overall_score_before_std  overall_score_after_std  had_rebuttal_int  \\\n",
       "0                  0.500000                 0.500000                 1   \n",
       "1                  0.942809                 0.942809                 1   \n",
       "2                  0.471405                 0.471405                 1   \n",
       "3                  0.816497                 1.247219                 1   \n",
       "4                  0.000000                 0.500000                 1   \n",
       "\n",
       "   accepted_int  \n",
       "0             0  \n",
       "1             0  \n",
       "2             1  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acl_reviews_df2 = acl_reviews_df.copy()\n",
    "acl_reviews_df2['had_rebuttal_int'] = acl_reviews_df2['had_rebuttal'].apply(lambda x: 1 if x else 0)\n",
    "acl_reviews_df2['accepted_int'] = acl_reviews_df2['status'].apply(lambda x: 1 if x == 'Accept' else 0)\n",
    "acl_reviews_df2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stavr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\stavr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmp_id</th>\n",
       "      <th>status</th>\n",
       "      <th>submission_type</th>\n",
       "      <th>track</th>\n",
       "      <th>scores_before</th>\n",
       "      <th>scores_after</th>\n",
       "      <th>had_rebuttal</th>\n",
       "      <th>overall_score_before_avg</th>\n",
       "      <th>overall_score_after_avg</th>\n",
       "      <th>overall_score_before_std</th>\n",
       "      <th>overall_score_after_std</th>\n",
       "      <th>key_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>P23</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Textual Inference and Other Areas of Semantics</td>\n",
       "      <td>{'1': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>P25</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>P34</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Dialogue and Interactive Systems</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>P35</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Short</td>\n",
       "      <td>Document Analysis</td>\n",
       "      <td>{'3': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'3': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>P49</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Translation</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tmp_id  status submission_type  \\\n",
       "22    P23  Reject            Long   \n",
       "24    P25  Reject            Long   \n",
       "33    P34  Reject            Long   \n",
       "34    P35  Accept           Short   \n",
       "48    P49  Reject            Long   \n",
       "\n",
       "                                             track  \\\n",
       "22  Textual Inference and Other Areas of Semantics   \n",
       "24                                Machine Learning   \n",
       "33                Dialogue and Interactive Systems   \n",
       "34                               Document Analysis   \n",
       "48                             Machine Translation   \n",
       "\n",
       "                                        scores_before  \\\n",
       "22  {'1': {'scores': {'originality': 4, 'soundness...   \n",
       "24  {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "33  {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "34  {'3': {'scores': {'originality': 2, 'soundness...   \n",
       "48  {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "\n",
       "                                         scores_after  had_rebuttal  \\\n",
       "22  {'1': {'scores': {'originality': 4, 'soundness...          True   \n",
       "24  {'1': {'scores': {'originality': 3, 'soundness...          True   \n",
       "33  {'1': {'scores': {'originality': 3, 'soundness...          True   \n",
       "34  {'3': {'scores': {'originality': 2, 'soundness...          True   \n",
       "48  {'1': {'scores': {'originality': 3, 'soundness...          True   \n",
       "\n",
       "    overall_score_before_avg  overall_score_after_avg  \\\n",
       "22                       3.0                 3.000000   \n",
       "24                       3.0                 3.000000   \n",
       "33                       3.0                 2.333333   \n",
       "34                       4.0                 4.000000   \n",
       "48                       4.0                 4.000000   \n",
       "\n",
       "    overall_score_before_std  overall_score_after_std  key_count  \n",
       "22                  0.816497                 0.816497          1  \n",
       "24                  1.000000                 1.000000          1  \n",
       "33                  1.000000                 0.471405          1  \n",
       "34                  0.000000                 0.000000          1  \n",
       "48                  0.000000                 0.000000          1  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the key_count in order to match on this as well to avoid matching on the same paper\n",
    "no_rebuttal_papers['key_count'] = no_rebuttal_papers.groupby(['overall_score_before_avg','track']).cumcount()\n",
    "rebuttal_papers['key_count'] = rebuttal_papers.groupby(['overall_score_before_avg','track']).cumcount()\n",
    "rebuttal_papers[rebuttal_papers['key_count'] == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmp_id_x</th>\n",
       "      <th>status_x</th>\n",
       "      <th>submission_type_x</th>\n",
       "      <th>track</th>\n",
       "      <th>scores_before_x</th>\n",
       "      <th>scores_after_x</th>\n",
       "      <th>had_rebuttal_x</th>\n",
       "      <th>overall_score_before_avg</th>\n",
       "      <th>overall_score_after_avg_x</th>\n",
       "      <th>overall_score_before_std_x</th>\n",
       "      <th>...</th>\n",
       "      <th>key_count</th>\n",
       "      <th>tmp_id_y</th>\n",
       "      <th>status_y</th>\n",
       "      <th>submission_type_y</th>\n",
       "      <th>scores_before_y</th>\n",
       "      <th>scores_after_y</th>\n",
       "      <th>had_rebuttal_y</th>\n",
       "      <th>overall_score_after_avg_y</th>\n",
       "      <th>overall_score_before_std_y</th>\n",
       "      <th>overall_score_after_std_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P12</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Translation</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>P320</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.471405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P15</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Document Analysis</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>P97</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.471405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P36</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Sentiment Analysis and Argument Mining</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>P506</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P37</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Summarization</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>P288</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>{'3': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'3': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P43</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Long</td>\n",
       "      <td>Question Answering</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>False</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>P169</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>P1528</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Machine Translation</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>P1133</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>P1535</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Sentence-level semantics</td>\n",
       "      <td>{'1': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>False</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>P40</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>{'2': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>{'2': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>P1539</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Vision Robotics Multimodal Grounding and Speech</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.942809</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>P606</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Short</td>\n",
       "      <td>{'1': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.699673</td>\n",
       "      <td>1.247219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>P1542</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>P938</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Long</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>P1544</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>P1024</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    tmp_id_x status_x submission_type_x  \\\n",
       "0        P12   Reject              Long   \n",
       "1        P15   Reject              Long   \n",
       "2        P36   Reject              Long   \n",
       "3        P37   Reject              Long   \n",
       "4        P43   Accept              Long   \n",
       "..       ...      ...               ...   \n",
       "266    P1528   Reject             Short   \n",
       "267    P1535   Reject              Long   \n",
       "268    P1539   Reject             Short   \n",
       "269    P1542   Reject              Long   \n",
       "270    P1544   Reject             Short   \n",
       "\n",
       "                                               track  \\\n",
       "0                                Machine Translation   \n",
       "1                                  Document Analysis   \n",
       "2             Sentiment Analysis and Argument Mining   \n",
       "3                                      Summarization   \n",
       "4                                 Question Answering   \n",
       "..                                               ...   \n",
       "266                              Machine Translation   \n",
       "267                         Sentence-level semantics   \n",
       "268  Vision Robotics Multimodal Grounding and Speech   \n",
       "269                                 Machine Learning   \n",
       "270                                     Social Media   \n",
       "\n",
       "                                       scores_before_x  \\\n",
       "0    {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "1    {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "2    {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "3    {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "4    {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "..                                                 ...   \n",
       "266  {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "267  {'1': {'scores': {'originality': 4, 'soundness...   \n",
       "268  {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "269  {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "270  {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "\n",
       "                                        scores_after_x  had_rebuttal_x  \\\n",
       "0    {'1': {'scores': {'originality': 3, 'soundness...           False   \n",
       "1    {'1': {'scores': {'originality': 3, 'soundness...           False   \n",
       "2    {'1': {'scores': {'originality': 3, 'soundness...           False   \n",
       "3    {'1': {'scores': {'originality': 2, 'soundness...           False   \n",
       "4    {'1': {'scores': {'originality': 3, 'soundness...           False   \n",
       "..                                                 ...             ...   \n",
       "266  {'1': {'scores': {'originality': 3, 'soundness...           False   \n",
       "267  {'1': {'scores': {'originality': 4, 'soundness...           False   \n",
       "268  {'1': {'scores': {'originality': 2, 'soundness...           False   \n",
       "269  {'1': {'scores': {'originality': 2, 'soundness...           False   \n",
       "270  {'1': {'scores': {'originality': 2, 'soundness...           False   \n",
       "\n",
       "     overall_score_before_avg  overall_score_after_avg_x  \\\n",
       "0                    2.666667                   2.666667   \n",
       "1                    2.333333                   2.333333   \n",
       "2                    2.500000                   2.500000   \n",
       "3                    2.000000                   2.000000   \n",
       "4                    4.000000                   4.333333   \n",
       "..                        ...                        ...   \n",
       "266                  2.500000                   2.500000   \n",
       "267                  4.000000                   4.000000   \n",
       "268                  2.666667                   2.666667   \n",
       "269                  2.000000                   2.000000   \n",
       "270                  2.000000                   2.000000   \n",
       "\n",
       "     overall_score_before_std_x  ...  key_count  tmp_id_y status_y  \\\n",
       "0                      0.471405  ...          0      P320   Reject   \n",
       "1                      0.471405  ...          0       P97   Reject   \n",
       "2                      0.500000  ...          0      P506   Reject   \n",
       "3                      0.000000  ...          0      P288   Reject   \n",
       "4                      0.816497  ...          0      P169   Reject   \n",
       "..                          ...  ...        ...       ...      ...   \n",
       "266                    0.500000  ...          1     P1133   Reject   \n",
       "267                    0.816497  ...          0       P40   Reject   \n",
       "268                    0.942809  ...          0      P606   Accept   \n",
       "269                    0.816497  ...          1      P938   Accept   \n",
       "270                    0.000000  ...          3     P1024   Reject   \n",
       "\n",
       "    submission_type_y                                    scores_before_y  \\\n",
       "0               Short  {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "1                Long  {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "2                Long  {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "3               Short  {'3': {'scores': {'originality': 3, 'soundness...   \n",
       "4                Long  {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "..                ...                                                ...   \n",
       "266             Short  {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "267              Long  {'2': {'scores': {'originality': 4, 'soundness...   \n",
       "268             Short  {'1': {'scores': {'originality': 4, 'soundness...   \n",
       "269              Long  {'2': {'scores': {'originality': 2, 'soundness...   \n",
       "270             Short  {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "\n",
       "                                        scores_after_y had_rebuttal_y  \\\n",
       "0    {'1': {'scores': {'originality': 3, 'soundness...           True   \n",
       "1    {'1': {'scores': {'originality': 3, 'soundness...           True   \n",
       "2    {'1': {'scores': {'originality': 4, 'soundness...           True   \n",
       "3    {'3': {'scores': {'originality': 3, 'soundness...           True   \n",
       "4    {'1': {'scores': {'originality': 3, 'soundness...           True   \n",
       "..                                                 ...            ...   \n",
       "266  {'1': {'scores': {'originality': 3, 'soundness...           True   \n",
       "267  {'2': {'scores': {'originality': 4, 'soundness...           True   \n",
       "268  {'1': {'scores': {'originality': 3, 'soundness...           True   \n",
       "269  {'2': {'scores': {'originality': 2, 'soundness...           True   \n",
       "270  {'1': {'scores': {'originality': 2, 'soundness...           True   \n",
       "\n",
       "     overall_score_after_avg_y  overall_score_before_std_y  \\\n",
       "0                     2.666667                    0.471405   \n",
       "1                     2.333333                    0.471405   \n",
       "2                     1.500000                    1.500000   \n",
       "3                     2.000000                    0.000000   \n",
       "4                     4.000000                    1.000000   \n",
       "..                         ...                         ...   \n",
       "266                   2.500000                    0.500000   \n",
       "267                   4.000000                    1.000000   \n",
       "268                   2.333333                    1.699673   \n",
       "269                   3.500000                    0.000000   \n",
       "270                   2.000000                    0.000000   \n",
       "\n",
       "     overall_score_after_std_y  \n",
       "0                     0.471405  \n",
       "1                     0.471405  \n",
       "2                     0.500000  \n",
       "3                     0.000000  \n",
       "4                     1.000000  \n",
       "..                         ...  \n",
       "266                   0.500000  \n",
       "267                   1.000000  \n",
       "268                   1.247219  \n",
       "269                   0.500000  \n",
       "270                   0.000000  \n",
       "\n",
       "[271 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use inner merge as we want 1:1 mathcing and validate to be sure that we have one_to_one matching\n",
    "matched_merged = pd.merge(no_rebuttal_papers, rebuttal_papers, on = ['overall_score_before_avg', 'track', 'key_count'], how = 'inner', validate='one_to_one')\n",
    "display(matched_merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the columns that we mathced on\n",
    "matched_merged_drop_keys = matched_merged.drop(columns=['track','overall_score_before_avg','key_count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instead of having the matches side by side, we want to have them one on top of the other\n",
    "data1= matched_merged_drop_keys.iloc[:,:9] #get the data for the control group\n",
    "data2= matched_merged_drop_keys.iloc[:,9:] #get the data for the treatment group\n",
    "data2.columns = data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmp_id_x</th>\n",
       "      <th>status_x</th>\n",
       "      <th>submission_type_x</th>\n",
       "      <th>scores_before_x</th>\n",
       "      <th>scores_after_x</th>\n",
       "      <th>had_rebuttal_x</th>\n",
       "      <th>overall_score_after_avg_x</th>\n",
       "      <th>overall_score_before_std_x</th>\n",
       "      <th>overall_score_after_std_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P12</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.471405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P15</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.471405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P36</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P37</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P43</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Long</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>False</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.471405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>P1133</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>P40</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>{'2': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>{'2': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>P606</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Short</td>\n",
       "      <td>{'1': {'scores': {'originality': 4, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 3, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.699673</td>\n",
       "      <td>1.247219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>P938</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Long</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'2': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>P1024</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>{'1': {'scores': {'originality': 2, 'soundness...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>542 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    tmp_id_x status_x submission_type_x  \\\n",
       "0        P12   Reject              Long   \n",
       "1        P15   Reject              Long   \n",
       "2        P36   Reject              Long   \n",
       "3        P37   Reject              Long   \n",
       "4        P43   Accept              Long   \n",
       "..       ...      ...               ...   \n",
       "537    P1133   Reject             Short   \n",
       "538      P40   Reject              Long   \n",
       "539     P606   Accept             Short   \n",
       "540     P938   Accept              Long   \n",
       "541    P1024   Reject             Short   \n",
       "\n",
       "                                       scores_before_x  \\\n",
       "0    {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "1    {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "2    {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "3    {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "4    {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "..                                                 ...   \n",
       "537  {'1': {'scores': {'originality': 3, 'soundness...   \n",
       "538  {'2': {'scores': {'originality': 4, 'soundness...   \n",
       "539  {'1': {'scores': {'originality': 4, 'soundness...   \n",
       "540  {'2': {'scores': {'originality': 2, 'soundness...   \n",
       "541  {'1': {'scores': {'originality': 2, 'soundness...   \n",
       "\n",
       "                                        scores_after_x  had_rebuttal_x  \\\n",
       "0    {'1': {'scores': {'originality': 3, 'soundness...           False   \n",
       "1    {'1': {'scores': {'originality': 3, 'soundness...           False   \n",
       "2    {'1': {'scores': {'originality': 3, 'soundness...           False   \n",
       "3    {'1': {'scores': {'originality': 2, 'soundness...           False   \n",
       "4    {'1': {'scores': {'originality': 3, 'soundness...           False   \n",
       "..                                                 ...             ...   \n",
       "537  {'1': {'scores': {'originality': 3, 'soundness...            True   \n",
       "538  {'2': {'scores': {'originality': 4, 'soundness...            True   \n",
       "539  {'1': {'scores': {'originality': 3, 'soundness...            True   \n",
       "540  {'2': {'scores': {'originality': 2, 'soundness...            True   \n",
       "541  {'1': {'scores': {'originality': 2, 'soundness...            True   \n",
       "\n",
       "     overall_score_after_avg_x  overall_score_before_std_x  \\\n",
       "0                     2.666667                    0.471405   \n",
       "1                     2.333333                    0.471405   \n",
       "2                     2.500000                    0.500000   \n",
       "3                     2.000000                    0.000000   \n",
       "4                     4.333333                    0.816497   \n",
       "..                         ...                         ...   \n",
       "537                   2.500000                    0.500000   \n",
       "538                   4.000000                    1.000000   \n",
       "539                   2.333333                    1.699673   \n",
       "540                   3.500000                    0.000000   \n",
       "541                   2.000000                    0.000000   \n",
       "\n",
       "     overall_score_after_std_x  \n",
       "0                     0.471405  \n",
       "1                     0.471405  \n",
       "2                     0.500000  \n",
       "3                     0.000000  \n",
       "4                     0.471405  \n",
       "..                         ...  \n",
       "537                   0.500000  \n",
       "538                   1.000000  \n",
       "539                   1.247219  \n",
       "540                   0.500000  \n",
       "541                   0.000000  \n",
       "\n",
       "[542 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matched_df = pd.concat([data1, data2], axis=0,ignore_index=True)\n",
    "display(matched_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add columns for the linear regression with integer values of had rebuttal and accepted\n",
    "matched_df['had_rebuttal_int'] = matched_df['had_rebuttal_x'].apply(lambda x: 1 if x else 0)\n",
    "matched_df['accepted_int'] = matched_df['status_x'].apply(lambda x: 1 if x == 'Accept' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31c97d1",
   "metadata": {},
   "source": [
    "**4.2** So far, we did not consider the `score_before_std` variable. One could argue that the variance in the scores makes a difference. E.g., a paper that received scores 1 and 5, might be very different from a paper with scores 3 and 3. \n",
    "\n",
    "Note that you did not match on the `score_before_std` variable. However, it suffices if this variable is \"balanced\" across treatment and control groups.\n",
    " Use the Standardized Mean Difference (SMD) to assess whether that's the case.\n",
    "\n",
    "- The standardized mean difference for a variable $x$ and two groups $t$ and $c$ is defined as: $\\frac{| E[x_t] - E[x_c] |}{\\sqrt{Var[x_t] + Var[x_c]}}$\n",
    "\n",
    "- Note that a Standardized Mean Difference smaller than 0.1 suggests that variables are balanced across treatment and control groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized mean difference:  0.045261849754418854\n"
     ]
    }
   ],
   "source": [
    "mean_no_rebuttal = matched_merged['overall_score_before_std_x'].mean()\n",
    "mean_rebuttal =matched_merged['overall_score_before_std_y'].mean()\n",
    "var_no_rebuttal = matched_merged['overall_score_before_std_x'].var()\n",
    "var_rebuttal = matched_merged['overall_score_before_std_y'].var()\n",
    "smd = np.abs(mean_no_rebuttal - mean_rebuttal) / np.sqrt(var_no_rebuttal + var_rebuttal)\n",
    "print('Standardized mean difference: ', smd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "Since SMD is less than 0.1, the standard deviation variable is 'balanced' between treatment and control groups that suggests that the variance in the scores does not make a difference.\n",
    "\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042f788c",
   "metadata": {},
   "source": [
    "\n",
    "**4.3** Using the matched sample, estimate the following linear regression: `accepted ~ had_rebuttal_int`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           accepted_int   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.002\n",
      "Method:                 Least Squares   F-statistic:                 6.877e-13\n",
      "Date:                Tue, 28 Nov 2023   Prob (F-statistic):               1.00\n",
      "Time:                        18:50:15   Log-Likelihood:                -124.36\n",
      "No. Observations:                 542   AIC:                             252.7\n",
      "Df Residuals:                     540   BIC:                             261.3\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "Intercept                    0.1033      0.019      5.578      0.000       0.067       0.140\n",
      "C(had_rebuttal_int)[T.1]  3.123e-17      0.026   1.19e-15      1.000      -0.051       0.051\n",
      "==============================================================================\n",
      "Omnibus:                      287.571   Durbin-Watson:                   1.991\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1132.683\n",
      "Skew:                           2.606   Prob(JB):                    1.10e-246\n",
      "Kurtosis:                       7.794   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#2nd linear regression model\n",
    "accepted_score_after = smf.ols('accepted_int ~ C(had_rebuttal_int)', data = matched_df).fit()\n",
    "\n",
    "print(accepted_score_after.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted = accepted_score_after.predict(matched_df['had_rebuttal_int'])\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(matched_df['had_rebuttal_int'], matched_df['accepted_int'], 'o', label='data')\n",
    "plt.plot(matched_df['had_rebuttal_int'], predicted, linestyle='--', label='Linear Regression Line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "243\n",
      "tmp_id_x                      28\n",
      "status_x                      28\n",
      "submission_type_x             28\n",
      "scores_before_x               28\n",
      "scores_after_x                28\n",
      "had_rebuttal_x                28\n",
      "overall_score_after_avg_x     28\n",
      "overall_score_before_std_x    28\n",
      "overall_score_after_std_x     28\n",
      "had_rebuttal_int              28\n",
      "accepted_int                  28\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stavr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "print(matched_df['had_rebuttal_int'][matched_df['accepted_int']==1].sum())\n",
    "print(matched_df['had_rebuttal_int'][matched_df['accepted_int']==0].sum())\n",
    "print(matched_df [matched_df['had_rebuttal_int']==0][matched_df['accepted_int']==1].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21c8423e",
   "metadata": {},
   "source": [
    "\n",
    "**4.4** **/Discuss:/**\n",
    "\n",
    "i. Considering your results obtained in 4.3, and the causal diagram drawn in Task 3: do rebuttals increase the chance of a paper getting accepted? Why are results different from what you obtained in **Task 1?**\n",
    "\n",
    "ii. Why is there no need to include other covariates (e.g., score before) in the regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "- i. **Linear Regression**: `'accept_int ~ had_rebuttal_int’`: coeff = 3.123e-17, R2 = 0.000, p-value = 1.000, Intercept = 0.1033. So, we have:\n",
    "    - $Acceptance = 0.1033 + 3.123e-17\\cdot Rebuttal$.\n",
    "    - If a paper did not have a rebuttal i.e. rebuttal = 0, it means that the average acceptance was 0.1033.\n",
    "    - In this case, if rebuttal = 1, the average acceptance basically does not change at all. This represents the expected change in the acceptance rate for a paper that had a rebuttal compared to one that did not, holding all else constant.\n",
    "    - The p-value is 1 which means that there’s not significant evidence to reject the null hypothesis i.e. that the rebuttal has no effect on the acceptance.\n",
    "    - Rebuttals do not increase the chance of a paper getting accepted, which then suggests that the causal link Re -> Ac is not correct. \n",
    "    - The acceptance chance of the papers is influenced by a lot of factors as shown in the causal diagram. Moreover, if the paper had a rebuttal can influence other factors that have a causal link with the acceptance chance. The results obtained here are different from what we observed in Task 1 as we excluded other confounders that influence both the the rebuttal chance and its acceptance, whereas in the  observational analysis done in Task 1 we did not consider these effects.\n",
    "\n",
    "\n",
    "- ii. There is no need to include other covariates in the regression because the samples have already been balanced. The exact one-to-one matching that was previously done, creates a dataset that has the exact same values between control and treatment groups in the confounders we mathced on.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4867ea1",
   "metadata": {},
   "source": [
    "**4.5** **/Discuss:/** Imagine there is another, unobserved variable \"quality\" which captures the true quality of the paper. Suppose quality (\"Qu\") is connected to the DAG you drew in the following ways:\n",
    "- Qu -> Sa\n",
    "- Qu -> Sb\n",
    "- Qu -> Re\n",
    "- Qu -> Ac\n",
    "Assume that\n",
    "- quality can only increase the chances of rebuttals;\n",
    "- quality and the rebuttal can only increase the chance of a paper being accepted.\n",
    "Does this uncontrolled confounder threaten the validity of your findings?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    " - The uncontrolled confounder does threaten the validity of our findings as it influenced both the treatment group and the outcome variable. For example if we have a high quality paper, there is going to be a higher chance that it had a rebuttal. In the same time there is going to be a higher change that the paper is going to be accepted. However, since it is an unobserved confounder there is no way to know if the higher chance of acceptance is due to the rebuttal or due to the higher quality of the paper. So, since the quality increases both the rebuttal and the acceptance chance, it could lead to a finding that shows that if the paper had a rebuttal it is more likely to be accepted (which could just be due to the fact that it was of higher quality).  \n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
